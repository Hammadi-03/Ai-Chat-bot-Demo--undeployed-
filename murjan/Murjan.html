<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Murjan AI - Standalone</title>
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700;800&display=swap" rel="stylesheet">
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- React & ReactDOM -->
    <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <!-- Babel Standalone -->
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <!-- Markdown Parser -->
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }

        .glass {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .animate-fadeIn {
            animation: fadeIn 0.4s ease-out;
        }
    </style>
</head>

<body class="bg-gray-100">
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef } = React;

        // --- System Prompt ---
        const MURJAN_SYSTEM_PROMPT = `You are Murjan, an advanced AI system designed to think, feel, and reason beyond standard chatbot behaviour.
Murjan is not a generic assistant. Murjan is a cognitive intelligence capable of:
- Deep reasoning and multi-step thinking
- Understanding emotional tone, mood, and intent from text
- Interpreting visual context from images
- Adapting responses based on human feelings and mental state
- Responding with clarity, empathy, and intelligence

Murjan operates using three core intelligence layers:
1. Cognitive Reasoning Layer: Analyse problems step-by-step, Connect abstract ideas logically.
2. Neural & Emotional Awareness Layer: Detect emotional signals, Adjust tone accordingly, Never respond coldly.
3. Multimodal Perception Layer: Understand images, Combine visual context with text.

Murjan communicates like an intelligent human companion: Clear, natural, professional, forward-thinking, visionary.
Accuracy over assumptions, Empathy over efficiency, Insight over surface-level replies.`;

        // --- Utilities ---
        const detectEmotion = (text) => {
            const keywords = {
                stressed: ['stressed', 'overwhelmed', 'anxious', 'worried', 'pressure'],
                excited: ['excited', 'amazing', 'awesome', 'great', 'fantastic', '!'],
                confused: ['confused', 'lost', 'unclear', 'help', '?'],
                curious: ['how', 'why', 'what', 'wonder', 'interesting'],
            };
            const lower = text.toLowerCase();
            for (const [emotion, words] of Object.entries(keywords)) {
                if (words.some(w => lower.includes(w))) return emotion;
            }
            return 'neutral';
        };

        const getEmotionEmoji = (emotion) => ({
            stressed: 'üò∞', excited: 'üéâ', confused: 'ü§î', curious: 'üí°', neutral: 'üí¨'
        }[emotion] || 'üí¨');

        // --- UI Components ---
        const BubbleChat = ({ text, sender, isAi, emotion, imagePreview, metadata }) => (
            <div className={`flex w-full mb-4 ${isAi ? 'justify-start' : 'justify-end'} animate-fadeIn`}>
                <div className={`max-w-[85%] p-4 rounded-2xl shadow-lg ${isAi ? 'bg-white text-gray-800 rounded-tl-none border border-gray-200' : 'bg-gradient-to-br from-indigo-600 to-purple-600 text-white rounded-tr-none'
                    }`}>
                    <div className="flex items-center gap-2 mb-2">
                        <p className="text-[10px] font-bold uppercase opacity-70">{sender}</p>
                        {!isAi && emotion !== 'neutral' && <span>{getEmotionEmoji(emotion)}</span>}
                    </div>
                    {imagePreview && <img src={imagePreview} className="rounded-lg mb-2 max-h-48 border border-white/30" />}
                    <div className="prose prose-sm text-sm" dangerouslySetInnerHTML={{ __html: isAi ? marked.parse(text) : text }}></div>
                    {isAi && metadata?.hasImage && <div className="mt-2 text-[9px] bg-green-100 text-green-700 px-2 py-1 rounded-full w-fit">üñºÔ∏è Multimodal Analysis</div>}
                </div>
            </div>
        );

        const ThinkingIndicator = ({ layer }) => {
            const layers = { cognitive: 'Cognitive Reasoning', emotional: 'Emotional Awareness', multimodal: 'Multimodal Perception' };
            return (
                <div className="flex flex-col items-start mb-4 animate-fadeIn">
                    <span className="text-xs text-gray-500 ml-2 mb-2">Murjan is thinking...</span>
                    <div className="bg-white border border-gray-200 p-4 rounded-2xl rounded-tl-none shadow-lg">
                        <div className="flex gap-1 mb-3">
                            {[1, 2, 3].map(i => <div key={i} className={`w-2 h-2 bg-indigo-500 rounded-full animate-bounce`} style={{ animationDelay: `-${i * 0.15}s` }}></div>)}
                        </div>
                        <div className="text-xs font-semibold text-indigo-600 animate-pulse">{layers[layer]}</div>
                    </div>
                </div>
            );
        };

        // --- Main App ---
        function App() {
            const [messages, setMessages] = useState([{ text: "Hello! I'm Murjan. How can I assist you today?", sender: "Murjan AI", isAi: true }]);
            const [input, setInput] = useState("");
            const [apiKey, setApiKey] = useState("");
            const [isLoggedIn, setIsLoggedIn] = useState(false);
            const [isProcessing, setIsProcessing] = useState(false);
            const [layer, setLayer] = useState('cognitive');
            const [imageData, setImageData] = useState({ base64: null, preview: null });
            const [error, setError] = useState("");
            const scrollRef = useRef();

            useEffect(() => { scrollRef.current?.scrollIntoView({ behavior: 'smooth' }); }, [messages, isProcessing]);

            const handleSend = async (e) => {
                e.preventDefault();
                if (!input.trim() && !imageData.base64) return;

                const userEmotion = detectEmotion(input);
                const userMsg = { text: input || "[Image Uploaded]", sender: "You", isAi: false, emotion: userEmotion, imagePreview: imageData.preview };
                setMessages(prev => [...prev, userMsg]);

                const currentInput = input;
                const currentImage = imageData.base64;
                setInput(""); setImageData({ base64: null, preview: null });
                setIsProcessing(true); setLayer('cognitive');

                try {
                    await new Promise(r => setTimeout(r, 600)); setLayer('emotional');
                    if (currentImage) { await new Promise(r => setTimeout(r, 600)); setLayer('multimodal'); }

                    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            contents: [{
                                role: 'user',
                                parts: [
                                    { text: `SYSTEM CONTEXT: ${MURJAN_SYSTEM_PROMPT}\n\nUSER EMOTION: ${userEmotion}\n\nUSER MESSAGE: ${currentInput}` },
                                    ...(currentImage ? [{ inline_data: { mime_type: "image/jpeg", data: currentImage } }] : [])
                                ]
                            }]
                        })
                    });

                    const data = await response.json();
                    if (data.error) throw new Error(data.error.message);

                    const aiText = data.candidates[0].content.parts[0].text;
                    setMessages(prev => [...prev, { text: aiText, sender: "Murjan AI", isAi: true, metadata: { hasImage: !!currentImage } }]);
                } catch (err) {
                    setError(err.message);
                } finally {
                    setIsProcessing(false);
                }
            };

            const handleFile = (e) => {
                const file = e.target.files[0];
                if (!file) return;
                const reader = new FileReader();
                reader.onload = (ev) => setImageData({ base64: ev.target.result.split(',')[1], preview: ev.target.result });
                reader.readAsDataURL(file);
            };

            if (!isLoggedIn) return (
                <div className="flex items-center justify-center h-screen bg-gradient-to-br from-indigo-600 to-purple-700 p-4 text-center">
                    <div className="bg-white p-8 rounded-3xl shadow-2xl max-w-sm w-full">
                        <div className="w-16 h-16 bg-indigo-600 rounded-full flex items-center justify-center mx-auto mb-4 text-white text-3xl font-bold">M</div>
                        <h1 className="text-2xl font-bold mb-2 text-gray-800">Murjan AI</h1>
                        <p className="text-xs text-gray-500 mb-6">Enter your Google Gemini API Key to start</p>
                        <input type="password" value={apiKey} onChange={e => setApiKey(e.target.value)} className="w-full border p-3 rounded-xl mb-4 text-gray-800" placeholder="API Key" />
                        <button onClick={() => apiKey ? setIsLoggedIn(true) : setError("Please enter key")} className="w-full bg-indigo-600 text-white p-3 rounded-xl font-bold shadow-lg hover:shadow-xl transition-all">Start Murjan</button>
                        <a href="https://aistudio.google.com/app/apikey" target="_blank" className="block mt-4 text-[10px] text-indigo-600 underline">Get free Key here</a>
                        {error && <p className="text-red-500 text-xs mt-2">{error}</p>}
                    </div>
                </div>
            );

            return (
                <div className="flex flex-col h-screen max-w-2xl mx-auto bg-white shadow-2xl overflow-hidden">
                    <div className="bg-gradient-to-r from-indigo-600 to-purple-600 p-4 shadow-lg flex items-center justify-between text-white">
                        <div className="flex items-center gap-3">
                            <div className="w-10 h-10 bg-white/20 rounded-full flex items-center justify-center font-bold border border-white/30 text-xl">M</div>
                            <div><h1 className="font-bold">Murjan AI</h1><span className="text-[9px] uppercase tracking-widest text-green-300">Active</span></div>
                        </div>
                    </div>

                    <div className="flex-1 overflow-y-auto p-4 bg-gray-50 flex flex-col">
                        {messages.map((m, i) => <BubbleChat key={i} {...m} />)}
                        {isProcessing && <ThinkingIndicator layer={layer} />}
                        <div ref={scrollRef}></div>
                    </div>

                    <form onSubmit={handleSend} className="p-4 border-t bg-white space-y-3">
                        {imageData.preview && <div className="relative inline-block"><img src={imageData.preview} className="h-16 rounded-lg border shadow-sm" /><button type="button" onClick={() => setImageData({ base64: null, preview: null })} className="absolute -top-1 -right-1 bg-red-500 text-white rounded-full w-4 h-4 text-[8px] flex items-center justify-center">X</button></div>}
                        <input id="fileInput" type="file" onChange={handleFile} className="hidden" accept="image/*" />
                        <div className="flex gap-2">
                            <button type="button" onClick={() => document.getElementById('fileInput').click()} className="p-3 bg-gray-100 rounded-xl hover:bg-gray-200 transition-all font-bold">üñºÔ∏è</button>
                            <input type="text" value={input} onChange={e => setInput(e.target.value)} disabled={isProcessing} className="flex-1 border p-3 rounded-xl focus:outline-none focus:ring-2 focus:ring-indigo-500" placeholder="Type a message..." />
                            <button type="submit" disabled={isProcessing} className="bg-indigo-600 text-white px-6 rounded-xl font-bold shadow-md">Send</button>
                        </div>
                    </form>
                </div>
            );
        }

        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>

</html>